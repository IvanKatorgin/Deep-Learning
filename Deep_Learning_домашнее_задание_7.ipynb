{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOEqWgKrx5HpGSKJddqFZcz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvanKatorgin/Deep-Learning/blob/main/Deep_Learning_%D0%B4%D0%BE%D0%BC%D0%B0%D1%88%D0%BD%D0%B5%D0%B5_%D0%B7%D0%B0%D0%B4%D0%B0%D0%BD%D0%B8%D0%B5_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Курс \"Deep Learning\". Домашнее задание 7. Рекуррентные сети 2. Каторгин И.П."
      ],
      "metadata": {
        "id": "oFDHG9Xgp528"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание\n",
        "\n",
        "Задание 1\n",
        "\n",
        "Сгенерировать последовательности, которые бы состояли из цифр (от 0 до 9)\n",
        "и задавались следующим образом:\n",
        "\n",
        "x - последовательность цифр\n",
        "\n",
        "y1 = x1, y(i) = x(i) + x(1). Если y(i) >= 10, то y(i) = y(i) - 10\n",
        "\n",
        "Задача:\n",
        "- научить модель предсказывать y(i) по x(i)\n",
        "- пробовать RNN, LSTM, GRU\n",
        "\n",
        "Задание 2 (дополнительное и необязательное)\n",
        "\n",
        "применить LSTM для решения лекционного практического задания https://colab.research.google.com/drive/1_rNrPHl6sYHNp-xo2G6I_SmRGTSSeICL"
      ],
      "metadata": {
        "id": "vYRYgJ4yqWMb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yvZAtjsT_41t"
      },
      "outputs": [],
      "source": [
        "# загрузим библиотеки\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns, time, random, os, torch, re, tqdm\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 1"
      ],
      "metadata": {
        "id": "aAbTq1absXpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# функция генерации последовательностей\n",
        "def generate_sequence(length):\n",
        "    \"\"\"Генерирует последовательность x и вычисляет y по правилам задачи\"\"\"\n",
        "    x = [random.randint(0, 9) for _ in range(length)]\n",
        "    y = [x[0]]  # y1 = x1\n",
        "    for i in range(1, len(x)):\n",
        "        yi = x[i] + x[0]\n",
        "        if yi >= 10:\n",
        "            yi -= 10\n",
        "        y.append(yi)\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "vmclkeOMsZ3z"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример использования:\n",
        "x, y = generate_sequence(15)\n",
        "print(\"x:\", x)\n",
        "print(\"y:\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjx2anLjybQX",
        "outputId": "d6f9252e-edff-490e-c4ff-6349cff0f48c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: [0, 0, 1, 9, 0, 1, 9, 2, 7, 6, 9, 2, 2, 6, 4]\n",
            "y: [0, 0, 1, 9, 0, 1, 9, 2, 7, 6, 9, 2, 2, 6, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cоздадим обычную полносвязную сеть"
      ],
      "metadata": {
        "id": "Px_7nUS2Bq0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация данных\n",
        "def generate_data(num_samples=10000, seq_length=10):\n",
        "    X, Y = [], []\n",
        "    for _ in range(num_samples):\n",
        "        x = [random.randint(0, 9) for _ in range(seq_length)]\n",
        "        y = [x[0]]  # y1 = x1\n",
        "        for i in range(1, len(x)):\n",
        "            yi = x[i] + x[0]\n",
        "            if yi >= 10: yi -= 10\n",
        "            y.append(yi)\n",
        "        X.append(x)\n",
        "        Y.append(y)\n",
        "    return torch.tensor(X, dtype=torch.float32), torch.tensor(Y, dtype=torch.long)"
      ],
      "metadata": {
        "id": "nml0p6qCAJAs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Параметры\n",
        "SEQ_LENGTH = 10\n",
        "NUM_SAMPLES = 10000\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "by9hLVqZASw0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Датасет\n",
        "X, Y = generate_data(NUM_SAMPLES, SEQ_LENGTH)\n",
        "dataset = TensorDataset(X, Y)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "MXdT2v-MATxK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Модель\n",
        "class DigitPredictor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(1, 128)  # Принимает x(i)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)  # 10 классов (0-9)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        return self.fc3(x)"
      ],
      "metadata": {
        "id": "DlnHrYG9AZ3A"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DigitPredictor()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "MGjlE9ZpAcis"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение\n",
        "for epoch in range(10):\n",
        "    for batch_x, batch_y in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        # Обрабатываем каждый элемент последовательности\n",
        "        loss = 0\n",
        "        for i in range(SEQ_LENGTH):\n",
        "            x_i = batch_x[:, i].unsqueeze(1)  # Текущий x(i)\n",
        "            y_i = batch_y[:, i]  # Текущий y(i)\n",
        "            outputs = model(x_i)\n",
        "            loss += criterion(outputs, y_i)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch}, Loss: {loss.item() / SEQ_LENGTH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NXT1YfBAfk4",
        "outputId": "ed69cb9a-2aea-4be9-ffbe-09c0652ef20c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 2.305716705322266\n",
            "Epoch 1, Loss: 2.2970661163330077\n",
            "Epoch 2, Loss: 2.295778274536133\n",
            "Epoch 3, Loss: 2.2559749603271486\n",
            "Epoch 4, Loss: 2.315299415588379\n",
            "Epoch 5, Loss: 2.292628860473633\n",
            "Epoch 6, Loss: 2.248338317871094\n",
            "Epoch 7, Loss: 2.28228816986084\n",
            "Epoch 8, Loss: 2.231733703613281\n",
            "Epoch 9, Loss: 2.2355888366699217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка\n",
        "test_x, test_y = generate_data(1, SEQ_LENGTH)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = []\n",
        "    for i in range(SEQ_LENGTH):\n",
        "        output = model(test_x[0, i].unsqueeze(0))\n",
        "        pred = output.argmax().item()\n",
        "        preds.append(pred)\n",
        "    print(\"Real x:\", test_x[0].int().tolist())\n",
        "    print(\"Real y:\", test_y[0].tolist())\n",
        "    print(\"Pred y:\", preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-rgy78iADwC",
        "outputId": "f49d3c0b-bc6f-4725-97b3-e5d3806bf602"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real x: [9, 0, 0, 3, 4, 9, 4, 4, 2, 9]\n",
            "Real y: [9, 9, 9, 2, 3, 8, 3, 3, 1, 8]\n",
            "Pred y: [9, 0, 0, 3, 4, 9, 4, 4, 2, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ошибка высокая, предсказанный у практически не совпал с истинным"
      ],
      "metadata": {
        "id": "lmPrAlQ6FqfA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим RNN модель"
      ],
      "metadata": {
        "id": "zplsMw7YElCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Размер обучающей выборки и длина последовательности\n",
        "N = 10000\n",
        "S = 15\n",
        "\n",
        "# Параметры\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 10"
      ],
      "metadata": {
        "id": "Cvs9OxwjExb2"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация данных\n",
        "def generate_sequences(num_samples=N, seq_length=S):\n",
        "    X, Y = [], []\n",
        "    for _ in range(num_samples):\n",
        "        x = [random.randint(0, 9) for _ in range(seq_length)]\n",
        "        y = [x[0]]  # y1 = x1\n",
        "        for i in range(1, len(x)):\n",
        "            yi = x[i] + x[0]\n",
        "            if yi >= 10: yi -= 10\n",
        "            y.append(yi)\n",
        "        X.append(x)\n",
        "        Y.append(y)\n",
        "    return torch.tensor(X, dtype=torch.float32), torch.tensor(Y, dtype=torch.long)"
      ],
      "metadata": {
        "id": "oP22xYQlExb2"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание данных\n",
        "X, Y = generate_sequences()\n",
        "dataset = TensorDataset(X.unsqueeze(2), Y)  # Добавляем размерность канала\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "r6DsyC_lExb2"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Вывод обучающей выборки\n",
        "print(\"X.shape:\", X.shape)\n",
        "print(\"Y.shape:\", Y.shape)\n",
        "print(\"X[0]:\", X[0])\n",
        "print(\"Y[0]:\", Y[0])\n",
        "print(\"X[1]:\", X[1])\n",
        "print(\"Y[1]:\", Y[1])\n",
        "print(\"X[2]:\", X[2])\n",
        "print(\"Y[2]:\", Y[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e31bb0b-2b9d-46be-c3b9-0ce51a2244ee",
        "id": "B1F8YM66Exb3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape: torch.Size([10000, 15])\n",
            "Y.shape: torch.Size([10000, 15])\n",
            "X[0]: tensor([5., 9., 2., 4., 4., 3., 1., 3., 7., 2., 6., 0., 5., 7., 0.])\n",
            "Y[0]: tensor([5, 4, 7, 9, 9, 8, 6, 8, 2, 7, 1, 5, 0, 2, 5])\n",
            "X[1]: tensor([4., 5., 9., 3., 6., 5., 6., 3., 7., 8., 6., 8., 1., 7., 5.])\n",
            "Y[1]: tensor([4, 9, 3, 7, 0, 9, 0, 7, 1, 2, 0, 2, 5, 1, 9])\n",
            "X[2]: tensor([4., 4., 2., 2., 7., 7., 2., 7., 5., 6., 2., 9., 2., 3., 0.])\n",
            "Y[2]: tensor([4, 8, 6, 6, 1, 1, 6, 1, 9, 0, 6, 3, 6, 7, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# модель RNN\n",
        "class SequenceModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(input_size=1, hidden_size=128, batch_first=True)\n",
        "        self.fc = nn.Linear(128, 10)  # 10 классов (цифры 0-9)\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn_out, _ = self.rnn(x)  # [batch, seq_len, hidden_size]\n",
        "        return self.fc(rnn_out)    # [batch, seq_len, 10]"
      ],
      "metadata": {
        "id": "U3xrIHjPE3WW"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SequenceModel()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "XhmtwjTXExb3"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    total_loss = 0\n",
        "    for batch_x, batch_y in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_x)  # [batch, seq_len, 10]\n",
        "        loss = criterion(outputs.view(-1, 10), batch_y.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0366ea1-8e74-4194-cc0a-b54ecd3f191a",
        "id": "pK37F9VrExb3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.3030\n",
            "Epoch 2, Loss: 2.3015\n",
            "Epoch 3, Loss: 2.3004\n",
            "Epoch 4, Loss: 2.2735\n",
            "Epoch 5, Loss: 2.1780\n",
            "Epoch 6, Loss: 1.9775\n",
            "Epoch 7, Loss: 1.6480\n",
            "Epoch 8, Loss: 1.4062\n",
            "Epoch 9, Loss: 1.1900\n",
            "Epoch 10, Loss: 1.0528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка\n",
        "def predict(model, x):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(0).unsqueeze(2)\n",
        "        outputs = model(x_tensor)\n",
        "        return outputs.argmax(dim=2).squeeze().tolist()\n",
        "\n",
        "test_x, test_y = generate_sequences(1, SEQ_LENGTH)\n",
        "pred_y = predict(model, test_x[0])\n",
        "print(\"\\nTest:\")\n",
        "print(\"X:\", test_x[0].int().tolist())\n",
        "print(\"Real Y:\", test_y[0].tolist())\n",
        "print(\"Pred Y:\", pred_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8c3a575-dd48-4a68-c951-ad17e4be1c56",
        "id": "WUfI8QL5Exb3"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test:\n",
            "X: [9, 1, 1, 9, 4, 7, 6, 8, 1, 2]\n",
            "Real Y: [9, 0, 0, 8, 3, 6, 5, 7, 0, 1]\n",
            "Pred Y: [8, 9, 9, 6, 3, 7, 4, 7, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "По сравнению с обычной полносвязной моделью уже лучше, ошибка значительно меньше, но предсказанный у все равно часто ошибается"
      ],
      "metadata": {
        "id": "hcO6XxZPF2_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим LSTM модель"
      ],
      "metadata": {
        "id": "lPbcW-5xB9M1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Размер обучающей выборки и длина последовательности\n",
        "N = 10000\n",
        "S = 15\n",
        "\n",
        "# Параметры\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 10"
      ],
      "metadata": {
        "id": "xliTyT3Sy4ua"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация данных\n",
        "def generate_sequences(num_samples=N, seq_length=S):\n",
        "    X, Y = [], []\n",
        "    for _ in range(num_samples):\n",
        "        x = [random.randint(0, 9) for _ in range(seq_length)]\n",
        "        y = [x[0]]  # y1 = x1\n",
        "        for i in range(1, len(x)):\n",
        "            yi = x[i] + x[0]\n",
        "            if yi >= 10: yi -= 10\n",
        "            y.append(yi)\n",
        "        X.append(x)\n",
        "        Y.append(y)\n",
        "    return torch.tensor(X, dtype=torch.float32), torch.tensor(Y, dtype=torch.long)"
      ],
      "metadata": {
        "id": "lIO7CxilCkwU"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание данных\n",
        "X, Y = generate_sequences()\n",
        "dataset = TensorDataset(X.unsqueeze(2), Y)  # Добавляем размерность канала\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "UIGld6xEDRmt"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Вывод обучающей выборки\n",
        "print(\"X.shape:\", X.shape)\n",
        "print(\"Y.shape:\", Y.shape)\n",
        "print(\"X[0]:\", X[0])\n",
        "print(\"Y[0]:\", Y[0])\n",
        "print(\"X[1]:\", X[1])\n",
        "print(\"Y[1]:\", Y[1])\n",
        "print(\"X[2]:\", X[2])\n",
        "print(\"Y[2]:\", Y[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEUqvvZC_ill",
        "outputId": "37d775e3-0817-49a0-99ba-96c779082977"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape: torch.Size([10000, 15])\n",
            "Y.shape: torch.Size([10000, 15])\n",
            "X[0]: tensor([9., 1., 6., 1., 3., 5., 6., 0., 9., 1., 9., 1., 7., 3., 5.])\n",
            "Y[0]: tensor([9, 0, 5, 0, 2, 4, 5, 9, 8, 0, 8, 0, 6, 2, 4])\n",
            "X[1]: tensor([7., 9., 9., 6., 2., 6., 3., 6., 3., 1., 9., 7., 7., 2., 6.])\n",
            "Y[1]: tensor([7, 6, 6, 3, 9, 3, 0, 3, 0, 8, 6, 4, 4, 9, 3])\n",
            "X[2]: tensor([3., 2., 1., 9., 0., 2., 6., 5., 2., 4., 1., 2., 2., 7., 0.])\n",
            "Y[2]: tensor([3, 5, 4, 2, 3, 5, 9, 8, 5, 7, 4, 5, 5, 0, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Модель LSTM\n",
        "class SequenceModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size=1, hidden_size=128, batch_first=True)\n",
        "        self.fc = nn.Linear(128, 10)  # 10 классов (цифры 0-9)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)  # [batch, seq_len, hidden_size]\n",
        "        return self.fc(lstm_out)     # [batch, seq_len, 10]"
      ],
      "metadata": {
        "id": "JCl6IAmxDacg"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SequenceModel()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "Hz9VYsblDm8e"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    total_loss = 0\n",
        "    for batch_x, batch_y in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_x)  # [batch, seq_len, 10]\n",
        "        loss = criterion(outputs.view(-1, 10), batch_y.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT_3jpqoDwvm",
        "outputId": "a97c58d2-7ccf-45eb-c662-763dc416aa0f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.3002\n",
            "Epoch 2, Loss: 2.2554\n",
            "Epoch 3, Loss: 2.0442\n",
            "Epoch 4, Loss: 1.4677\n",
            "Epoch 5, Loss: 1.0413\n",
            "Epoch 6, Loss: 0.7861\n",
            "Epoch 7, Loss: 0.6164\n",
            "Epoch 8, Loss: 0.4937\n",
            "Epoch 9, Loss: 0.4008\n",
            "Epoch 10, Loss: 0.3301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка\n",
        "def predict(model, x):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(0).unsqueeze(2)\n",
        "        outputs = model(x_tensor)\n",
        "        return outputs.argmax(dim=2).squeeze().tolist()\n",
        "\n",
        "test_x, test_y = generate_sequences(1, SEQ_LENGTH)\n",
        "pred_y = predict(model, test_x[0])\n",
        "print(\"\\nTest:\")\n",
        "print(\"X:\", test_x[0].int().tolist())\n",
        "print(\"Real Y:\", test_y[0].tolist())\n",
        "print(\"Pred Y:\", pred_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmvE5q_4EJWv",
        "outputId": "75ab88e7-b5f1-438e-c094-ae16463542f5"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test:\n",
            "X: [3, 4, 4, 9, 9, 4, 0, 4, 4, 0]\n",
            "Real Y: [3, 7, 7, 2, 2, 7, 3, 7, 7, 3]\n",
            "Pred Y: [3, 7, 7, 2, 2, 7, 3, 7, 7, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предсказанный у практически не ошибается и совпадает с истинным"
      ],
      "metadata": {
        "id": "B3_6RP8aGHkW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим GRU модель"
      ],
      "metadata": {
        "id": "AVlOE92HGW8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Размер обучающей выборки и длина последовательности\n",
        "N = 10000\n",
        "S = 15\n",
        "\n",
        "# Параметры\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 10\n",
        "EMBEDDING_SIZE = 64\n",
        "HIDDEN_SIZE = 128"
      ],
      "metadata": {
        "id": "bclRBMr-GW8h"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация данных\n",
        "def generate_sequences(num_samples=N, seq_length=S):\n",
        "    X, Y = [], []\n",
        "    for _ in range(num_samples):\n",
        "        x = [random.randint(0, 9) for _ in range(seq_length)]\n",
        "        y = [x[0]]  # y1 = x1\n",
        "        for i in range(1, len(x)):\n",
        "            yi = x[i] + x[0]\n",
        "            if yi >= 10: yi -= 10\n",
        "            y.append(yi)\n",
        "        X.append(x)\n",
        "        Y.append(y)\n",
        "    return torch.tensor(X, dtype=torch.long), torch.tensor(Y, dtype=torch.long)"
      ],
      "metadata": {
        "id": "Qs6VRfmGGW8h"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание данных\n",
        "X, Y = generate_sequences()\n",
        "dataset = TensorDataset(X, Y)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "O3BofskoGW8h"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Вывод обучающей выборки\n",
        "print(\"X.shape:\", X.shape)\n",
        "print(\"Y.shape:\", Y.shape)\n",
        "print(\"X[0]:\", X[0])\n",
        "print(\"Y[0]:\", Y[0])\n",
        "print(\"X[1]:\", X[1])\n",
        "print(\"Y[1]:\", Y[1])\n",
        "print(\"X[2]:\", X[2])\n",
        "print(\"Y[2]:\", Y[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e72c6af-9632-4f84-89cf-fb351773bd1d",
        "id": "cG3yxxcxGW8i"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape: torch.Size([10000, 15])\n",
            "Y.shape: torch.Size([10000, 15])\n",
            "X[0]: tensor([0, 8, 9, 4, 9, 1, 6, 2, 5, 9, 6, 0, 6, 6, 3])\n",
            "Y[0]: tensor([0, 8, 9, 4, 9, 1, 6, 2, 5, 9, 6, 0, 6, 6, 3])\n",
            "X[1]: tensor([7, 8, 9, 9, 2, 4, 4, 9, 2, 5, 5, 1, 5, 6, 0])\n",
            "Y[1]: tensor([7, 5, 6, 6, 9, 1, 1, 6, 9, 2, 2, 8, 2, 3, 7])\n",
            "X[2]: tensor([5, 6, 0, 4, 2, 1, 4, 6, 9, 5, 0, 0, 3, 4, 8])\n",
            "Y[2]: tensor([5, 1, 5, 9, 7, 6, 9, 1, 4, 0, 5, 5, 8, 9, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Модель GRU с embedding\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, vocab_size=10, embed_size=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.gru = nn.GRU(embed_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: [batch, seq_len]\n",
        "        embedded = self.embedding(x)  # [batch, seq_len, embed_size]\n",
        "        gru_out, _ = self.gru(embedded)  # [batch, seq_len, hidden_size]\n",
        "        output = self.fc(gru_out)  # [batch, seq_len, vocab_size]\n",
        "        return output"
      ],
      "metadata": {
        "id": "tIkkLgx9KLEQ"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GRUModel()"
      ],
      "metadata": {
        "id": "Zw6QWg73IFs-"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "OXfjfZkiGW8j"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = nn.GRU(10,128, batch_first=True)\n",
        "o, s = rnn(torch.randn(64, 15, 10))\n",
        "o.shape, len(s), s[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bD7dDpIsIdsN",
        "outputId": "42d870eb-7d1e-4a23-a72b-9313050d80fc"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 15, 128]), 1, torch.Size([64, 128]))"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    total_loss = 0\n",
        "    for batch_x, batch_y in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_x) # [batch, seq_len, 10]\n",
        "        loss = criterion(outputs.view(-1, 10), batch_y.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cb11991-4858-4c78-dbc3-cdb31f3c3bdd",
        "id": "IRkBXVvcGW8j"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.2070\n",
            "Epoch 2, Loss: 0.6658\n",
            "Epoch 3, Loss: 0.0492\n",
            "Epoch 4, Loss: 0.0179\n",
            "Epoch 5, Loss: 0.0100\n",
            "Epoch 6, Loss: 0.0066\n",
            "Epoch 7, Loss: 0.0047\n",
            "Epoch 8, Loss: 0.0035\n",
            "Epoch 9, Loss: 0.0028\n",
            "Epoch 10, Loss: 0.0022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка\n",
        "def predict(model, x):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x_tensor = torch.tensor(x, dtype=torch.long).unsqueeze(0)\n",
        "        outputs = model(x_tensor)\n",
        "        return outputs.argmax(dim=2).squeeze().tolist()\n",
        "\n",
        "test_x, test_y = generate_sequences(1, SEQ_LENGTH)\n",
        "pred_y = predict(model, test_x[0])\n",
        "print(\"\\nTest:\")\n",
        "print(\"X:\", test_x[0].int().tolist())\n",
        "print(\"Real Y:\", test_y[0].tolist())\n",
        "print(\"Pred Y:\", pred_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce89ce00-05f8-4e4d-80be-8c2bb5625ddc",
        "id": "gwCEEzz9GW8k"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test:\n",
            "X: [7, 8, 1, 1, 6, 1, 0, 7, 5, 1]\n",
            "Real Y: [7, 5, 8, 8, 3, 8, 7, 4, 2, 8]\n",
            "Pred Y: [7, 5, 8, 8, 3, 8, 7, 4, 2, 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Из всех рассмотренных моделей, эта модель наиболее точная"
      ],
      "metadata": {
        "id": "RAsg-YePLXpi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 2"
      ],
      "metadata": {
        "id": "gdskTuwpsaQM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArE9Sysh5EDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab9d5fb8-eeec-4c86-87f8-af49ee1d9c5a"
      },
      "source": [
        "# загрузим датасет\n",
        "with open('nietzsche.txt', encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "print('length:', len(text))\n",
        "text = re.sub('[^a-z ]', ' ', text)\n",
        "text = re.sub('\\s+', ' ', text)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length: 600893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ijyo7gcL49kz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2415527d-b028-40a9-8b49-27d589b4a8f3"
      },
      "source": [
        "text[:100]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'preface supposing that truth is a woman what then is there not ground for suspecting that all philos'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNiH2xET5HxF"
      },
      "source": [
        "INDEX_TO_CHAR = sorted(list(set(text)))\n",
        "CHAR_TO_INDEX = {c: i for i, c in enumerate(INDEX_TO_CHAR)}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAer4W2RYfhr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "407001e7-f215-4a62-a638-7e5b8c440115"
      },
      "source": [
        "CHAR_TO_INDEX"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " 'a': 1,\n",
              " 'b': 2,\n",
              " 'c': 3,\n",
              " 'd': 4,\n",
              " 'e': 5,\n",
              " 'f': 6,\n",
              " 'g': 7,\n",
              " 'h': 8,\n",
              " 'i': 9,\n",
              " 'j': 10,\n",
              " 'k': 11,\n",
              " 'l': 12,\n",
              " 'm': 13,\n",
              " 'n': 14,\n",
              " 'o': 15,\n",
              " 'p': 16,\n",
              " 'q': 17,\n",
              " 'r': 18,\n",
              " 's': 19,\n",
              " 't': 20,\n",
              " 'u': 21,\n",
              " 'v': 22,\n",
              " 'w': 23,\n",
              " 'x': 24,\n",
              " 'y': 25,\n",
              " 'z': 26}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4EeJBub5ueL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5205e314-b8ec-4513-d50f-a0a9cd5e027a"
      },
      "source": [
        "MAX_LEN = 40\n",
        "STEP = 3\n",
        "SENTENCES = []\n",
        "NEXT_CHARS = []\n",
        "for i in range(0, len(text) - MAX_LEN, STEP):\n",
        "    SENTENCES.append(text[i: i + MAX_LEN])\n",
        "    NEXT_CHARS.append(text[i + MAX_LEN])\n",
        "print('Num sents:', len(SENTENCES))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num sents: 193075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHPHQII_6MUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a98a0a01-a027-44ff-aa87-8b521b6a69a3"
      },
      "source": [
        "print('Vectorization...')\n",
        "X = torch.zeros((len(SENTENCES), MAX_LEN), dtype=int)\n",
        "Y = torch.zeros((len(SENTENCES)), dtype=int)\n",
        "for i, sentence in enumerate(SENTENCES):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t] = CHAR_TO_INDEX[char]\n",
        "    Y[i] = CHAR_TO_INDEX[NEXT_CHARS[i]]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorization...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7MP7Jzi7PAN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "159ebeb0-0678-410f-8d1f-de1fe229df61"
      },
      "source": [
        "X[0:1], Y[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[16, 18,  5,  6,  1,  3,  5,  0, 19, 21, 16, 16, 15, 19,  9, 14,  7,  0,\n",
              "          20,  8,  1, 20,  0, 20, 18, 21, 20,  8,  0,  9, 19,  0,  1,  0, 23, 15,\n",
              "          13,  1, 14,  0]]),\n",
              " tensor(23))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XKb2CyB6nwL"
      },
      "source": [
        "BATCH_SIZE=512\n",
        "dataset = torch.utils.data.TensorDataset(X, Y)\n",
        "data = torch.utils.data.DataLoader(dataset, BATCH_SIZE, shuffle=True)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, rnnClass, dictionary_size, embedding_size, num_hiddens, num_classes):\n",
        "        super().__init__()\n",
        "        self.num_hiddens = num_hiddens\n",
        "        self.embedding = nn.Embedding(dictionary_size, embedding_size)\n",
        "        self.hidden = rnnClass(embedding_size, num_hiddens, batch_first=True)\n",
        "        self.output = nn.Linear(num_hiddens, num_classes)\n",
        "\n",
        "    def forward(self, X):\n",
        "        out = self.embedding(X)\n",
        "        _, state = self.hidden(out)\n",
        "\n",
        "        # Обратотка как LSTM (состояние кортеж) так и GRU (состоние тензор)\n",
        "        if isinstance(state, tuple):  # LSTM case\n",
        "            hidden_state = state[0]  # Берем hidden_state, игнорируем cell_state\n",
        "        else:  # GRU case\n",
        "            hidden_state = state\n",
        "\n",
        "        predictions = self.output(hidden_state.squeeze(0))  # Удаляем пакетный размер при необходимости\n",
        "        return predictions"
      ],
      "metadata": {
        "id": "-GjQEva78g9P"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHDuSE8A7ssc"
      },
      "source": [
        "model = NeuralNetwork(nn.LSTM, len(CHAR_TO_INDEX), 64, 128, len(CHAR_TO_INDEX))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvKPD9L9zJal",
        "outputId": "f7d93c9c-d754-4574-d4ca-d0ca22959b77"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([193075, 40])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTCG-ESC74UK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f992ce9-5f43-4101-9ba8-7b68712105bf"
      },
      "source": [
        "model(X[0:1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0077,  0.0608, -0.0420, -0.0356,  0.0468,  0.0301, -0.0419, -0.0440,\n",
              "          0.1277,  0.0895, -0.0299, -0.0096,  0.0432, -0.0968, -0.1212,  0.0095,\n",
              "          0.0048,  0.1074,  0.0044, -0.1479,  0.0375,  0.1041, -0.0058,  0.0702,\n",
              "         -0.1288, -0.0989,  0.0166]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gch6FQl8x6Hj"
      },
      "source": [
        "embedding = nn.Embedding(len(INDEX_TO_CHAR), 15)\n",
        "rnn = nn.LSTM(15,128, batch_first=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o, s = rnn(embedding(X[0:10]))\n",
        "print(o.shape, s[0].shape, s[1].shape)  # LSTM возвращает кортеж (hidden_state, cell_state)"
      ],
      "metadata": {
        "id": "CYavLEuY7VEs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6cd9e0d-f87d-4de8-ab12-3cfdfdab6538"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 40, 128]) torch.Size([1, 10, 128]) torch.Size([1, 10, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbeKFkwdFclg"
      },
      "source": [
        "model = model.cuda()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQpkKJV_76dq"
      },
      "source": [
        "def sample(preds):\n",
        "    softmaxed = torch.softmax(preds, 0)\n",
        "    probas = torch.distributions.multinomial.Multinomial(1, softmaxed).sample()\n",
        "    return probas.argmax()\n",
        "\n",
        "def generate_text():\n",
        "    start_index = random.randint(0, len(text) - MAX_LEN - 1)\n",
        "\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + MAX_LEN]\n",
        "    generated += sentence\n",
        "\n",
        "    for i in range(MAX_LEN):\n",
        "        x_pred = torch.zeros((1, MAX_LEN), dtype=int)\n",
        "        for t, char in enumerate(generated[-MAX_LEN:]):\n",
        "            x_pred[0, t] = CHAR_TO_INDEX[char]\n",
        "\n",
        "        preds = model(x_pred.cuda())[0].cpu()\n",
        "        next_char = INDEX_TO_CHAR[sample(preds)]\n",
        "        generated = generated + next_char\n",
        "\n",
        "    print(generated[:MAX_LEN] + '|' + generated[MAX_LEN:])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EV09Ast97aQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca8a451d-ed92-4d1c-a05d-78347291bdce"
      },
      "source": [
        "generate_text()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f discernment luke improved he that humb|gjrvamgho aqdlyzurjaprvvpcmntqghitmait o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hylQYY8H_Lw2"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qshorynU9-Cx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1237f914-1eb1-4f45-8436-4e082911eb4e"
      },
      "source": [
        "for ep in range(100):\n",
        "    start = time.time()\n",
        "    train_loss = 0.\n",
        "    train_passed = 0\n",
        "\n",
        "    model.train()\n",
        "    for X_b, y_b in data:\n",
        "        X_b, y_b = X_b.cuda(), y_b.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        answers = model(X_b)\n",
        "        loss = criterion(answers, y_b)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_passed += 1\n",
        "\n",
        "    print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))\n",
        "    model.eval()\n",
        "    generate_text()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0. Time: 3.889, Train loss: 2.175\n",
            "nal influence of this metaphysical neces|tuan our ove ston to ceacing self whe re\n",
            "Epoch 1. Time: 3.964, Train loss: 1.801\n",
            "e is far less worthy of respect religion| masted gree a despes foroutd calle loct\n",
            "Epoch 2. Time: 3.360, Train loss: 1.662\n",
            "sight there must always exist an inheren|t undimarioubees dur there remandernging\n",
            "Epoch 3. Time: 3.526, Train loss: 1.576\n",
            " ears nowadays are unwilling to hear suc|celed bould for is he dighs peithers in \n",
            "Epoch 4. Time: 3.555, Train loss: 1.514\n",
            " which rends while it delights what and |nethy that the juch one sholigisio lat a\n",
            "Epoch 5. Time: 3.811, Train loss: 1.467\n",
            "on of european taste indeed who could do|rglave our converstionss to exerjectical\n",
            "Epoch 6. Time: 3.554, Train loss: 1.429\n",
            " epistles i x at the risk of displeasing| such obteremost ciluistion does is with\n",
            "Epoch 7. Time: 3.396, Train loss: 1.398\n",
            " also nothing more for men to do that is| appearnce is ording formably is most sp\n",
            "Epoch 8. Time: 3.973, Train loss: 1.372\n",
            "wise predicated of the cause that it is |refundament at would havative raction ar\n",
            "Epoch 9. Time: 3.407, Train loss: 1.350\n",
            "rned and venerable conceits and witticis|ul and sifted what was peoplets aut to t\n",
            "Epoch 10. Time: 3.562, Train loss: 1.331\n",
            "es not fade pale and die away as all ger|manievenest the him of along himself mai\n",
            "Epoch 11. Time: 3.962, Train loss: 1.314\n",
            " the only thing is that the prevailing v|irthere symparent proposidinal virtues o\n",
            "Epoch 12. Time: 3.464, Train loss: 1.299\n",
            " what am i saying to play the philosophe|r or ejust of the poince their seciation\n",
            "Epoch 13. Time: 3.581, Train loss: 1.285\n",
            "on but also to a bad and unjust one thin|king its doing in the buthly upleas of t\n",
            "Epoch 14. Time: 3.934, Train loss: 1.274\n",
            "h is at the same time young and aged too| lacks well hard charmne the reason of t\n",
            "Epoch 15. Time: 3.675, Train loss: 1.262\n",
            " from a thing of morality to a thing of |which reases afteric did as not pask is \n",
            "Epoch 16. Time: 3.606, Train loss: 1.251\n",
            "the discipline of science stands before |presersion of the one to the law batelit\n",
            "Epoch 17. Time: 3.912, Train loss: 1.240\n",
            "y and another when the impulse is to act|rality of hiddle coldication of equality\n",
            "Epoch 18. Time: 3.858, Train loss: 1.233\n",
            "ys however it is extraordinarily so thro|ugh strong whatever high ignifuly only f\n",
            "Epoch 19. Time: 3.678, Train loss: 1.223\n",
            "time world to tremble to the depths of t|he compara for himself were that always \n",
            "Epoch 20. Time: 3.540, Train loss: 1.214\n",
            " perhaps in every sense of the term and |taken alughting such awadays manifestes \n",
            "Epoch 21. Time: 4.024, Train loss: 1.208\n",
            "a little contempt for as regards his fre|es the detine is all to defining poet wi\n",
            "Epoch 22. Time: 3.643, Train loss: 1.199\n",
            "ght in the subject ready to digress from| to a qualities in himself was which let\n",
            "Epoch 23. Time: 4.032, Train loss: 1.192\n",
            "future is it true does there then remain|s sovely show pretwicable edouch mid the\n",
            "Epoch 24. Time: 4.111, Train loss: 1.186\n",
            "ed only by the extent to which the slave| deeming that again and he other formal \n",
            "Epoch 25. Time: 3.939, Train loss: 1.178\n",
            "ks the odour of paltry people clings to |god kind god hantfures we who has muth a\n",
            "Epoch 26. Time: 3.886, Train loss: 1.173\n",
            "is love so highly prized at the expense |of his child the destical or from the me\n",
            "Epoch 27. Time: 3.974, Train loss: 1.167\n",
            "niuses seek each other like man and woma|ns the contempation of very our perhaps \n",
            "Epoch 28. Time: 3.745, Train loss: 1.161\n",
            "d and so antithetical that it denies the| another as on look it form a various en\n",
            "Epoch 29. Time: 3.811, Train loss: 1.155\n",
            "our has inter pares neither significance| indercoud case and than a heart germans\n",
            "Epoch 30. Time: 3.972, Train loss: 1.150\n",
            "iginated men with a still natural nature| the whole strengtes of a become philoso\n",
            "Epoch 31. Time: 3.874, Train loss: 1.144\n",
            "ligious worship is the result of such co|ncearing type and above and expleastions\n",
            "Epoch 32. Time: 3.496, Train loss: 1.140\n",
            "dday of life oh season of delight my sum|ple peactic will how your intereption sp\n",
            "Epoch 33. Time: 4.263, Train loss: 1.136\n",
            "kes place beyond good and evil objection| is earth at a condination so endy and m\n",
            "Epoch 34. Time: 3.620, Train loss: 1.130\n",
            "y inferred for many of the most delightf|ul therenoth one with the object of hist\n",
            "Epoch 35. Time: 3.428, Train loss: 1.125\n",
            "ess in craft i could imagine that a man |like would be both untain matter moral i\n",
            "Epoch 36. Time: 3.988, Train loss: 1.120\n",
            "sible worlds since he is himself all goo|d alone to lask hows consoble to hort of\n",
            "Epoch 37. Time: 3.606, Train loss: 1.114\n",
            "est in and what are the things generally| and his nature which as operations in p\n",
            "Epoch 38. Time: 3.446, Train loss: 1.110\n",
            "of the same description the belief in im|moracieq value men look and head appear \n",
            "Epoch 39. Time: 4.665, Train loss: 1.106\n",
            "tions of life he risks himself constantl|y maze century of the potes the suremp a\n",
            "Epoch 40. Time: 3.606, Train loss: 1.102\n",
            "ccumulation and augmentation of human po|wers of the usen and licker that there i\n",
            "Epoch 41. Time: 3.677, Train loss: 1.097\n",
            "ld be the work of our organs it seems to| antiquity desires from finoty the past \n",
            "Epoch 42. Time: 3.828, Train loss: 1.093\n",
            "e god dionysus the great equivocator and| the universal simnization iosure extima\n",
            "Epoch 43. Time: 3.672, Train loss: 1.089\n",
            "tells insert twenty more therefore becau|se the present for the most perseafefues\n",
            "Epoch 44. Time: 3.720, Train loss: 1.085\n",
            "nto the origin of this belief all faith |of other supposers seeke to complete sti\n",
            "Epoch 45. Time: 3.654, Train loss: 1.082\n",
            "e pleasure of doing it how appearance be|ed too many race of said a sight of sort\n",
            "Epoch 46. Time: 3.953, Train loss: 1.077\n",
            "e most certain thing i know about myself| and previes under the soulard gradation\n",
            "Epoch 47. Time: 3.438, Train loss: 1.074\n",
            " in man serves as well for the elevation| capacity and decepts whered to among of\n",
            "Epoch 48. Time: 3.875, Train loss: 1.071\n",
            "duct and opinion will appear as narrow a|nd here we are valitions of dreads no qu\n",
            "Epoch 49. Time: 4.024, Train loss: 1.066\n",
            "and challenger of god and whosoever has |feelizen which personally in their new p\n",
            "Epoch 50. Time: 3.597, Train loss: 1.062\n",
            "bleness the mere apparentness of such ow|n discortion so dows in which happened t\n",
            "Epoch 51. Time: 3.436, Train loss: 1.058\n",
            "an would like to believe that love can d|emocratic possible self resultical speac\n",
            "Epoch 52. Time: 4.042, Train loss: 1.055\n",
            "ity how much delight morality occasions |of all man should nature coldenourtly fa\n",
            "Epoch 53. Time: 3.616, Train loss: 1.052\n",
            "iving in europe they know how to succeed|ence makes him that there us european ac\n",
            "Epoch 54. Time: 3.463, Train loss: 1.048\n",
            "ing nor retreating one is habituated to |be enchinity of olloness with remains sc\n",
            "Epoch 55. Time: 4.370, Train loss: 1.044\n",
            "ch at bottom he loves himself seems to b|e religions are quanace and must illage \n",
            "Epoch 56. Time: 3.634, Train loss: 1.042\n",
            "ereafter to which death is the portal th|e individual cults when they wantold of \n",
            "Epoch 57. Time: 3.485, Train loss: 1.039\n",
            "e spirits here a new problem here a long| conventive and distrustfluence notions \n",
            "Epoch 58. Time: 3.876, Train loss: 1.034\n",
            "f antiquity swarmed with sons of god he |cannor these man is well as the names hi\n",
            "Epoch 59. Time: 3.657, Train loss: 1.031\n",
            "f his mastery of the expedients here emp|loyence of plentivels poldness wortherto\n",
            "Epoch 60. Time: 3.688, Train loss: 1.029\n",
            "enerally one may say that woman would no|t we with its base and that is invention\n",
            "Epoch 61. Time: 3.525, Train loss: 1.026\n",
            "ir pranks it must have been the dart of |the good but the diffelence noth mence n\n",
            "Epoch 62. Time: 4.003, Train loss: 1.023\n",
            "nomic conditions the selecting and disci|ped to be type who danger moral the only\n",
            "Epoch 63. Time: 3.639, Train loss: 1.019\n",
            "re they reverence it is accustomed to st|rusting ehemy for which the suprity itse\n",
            "Epoch 64. Time: 3.465, Train loss: 1.016\n",
            "nd despicable the antithesis good and ev|en when one ruin of coghess sertant alis\n",
            "Epoch 65. Time: 4.141, Train loss: 1.014\n",
            "fe life itself as conditioned by the per|son to the deed books is forners within \n",
            "Epoch 66. Time: 3.622, Train loss: 1.012\n",
            "lves only the more refined forms of gove|r command is good indeupent is so contem\n",
            "Epoch 67. Time: 3.635, Train loss: 1.007\n",
            "e driven to it as the anti semites seem |nothing in the strength its unjoymes amo\n",
            "Epoch 68. Time: 3.859, Train loss: 1.005\n",
            "thin his discretion not to have done the| outher himself so much a subject observ\n",
            "Epoch 69. Time: 3.458, Train loss: 1.001\n",
            "would not one exchange these for truths |the contemplation what is a some obginis\n",
            "Epoch 70. Time: 3.950, Train loss: 1.000\n",
            "er restlessness the promiscuous flow of |sensal deceived a century or the futureo\n",
            "Epoch 71. Time: 4.048, Train loss: 0.998\n",
            "e distance and as it were the space arou|s to more dierders them that the moxtrel\n",
            "Epoch 72. Time: 3.612, Train loss: 0.995\n",
            "e should you who are mortal outwear your| accorded requires because as in the foo\n",
            "Epoch 73. Time: 3.475, Train loss: 0.992\n",
            "man indispensable for the morrow and the| highest freedom threat a docksible whic\n",
            "Epoch 74. Time: 3.642, Train loss: 0.990\n",
            "m schopenhauer has perhaps become more a|s i humanity and requires it rests court\n",
            "Epoch 75. Time: 3.839, Train loss: 0.987\n",
            " also the element of demerit in its rela|tive might insigification and had been f\n",
            "Epoch 76. Time: 3.597, Train loss: 0.984\n",
            "ething precious christianity gave eros p|uds as the senteness may part of like hi\n",
            "Epoch 77. Time: 3.671, Train loss: 0.982\n",
            "efensive against all that is sorrowful a|s inspired relation of the elevity and i\n",
            "Epoch 78. Time: 3.810, Train loss: 0.980\n",
            "s hitherto been treated by men like bird|ness at time their had life and her caus\n",
            "Epoch 79. Time: 3.588, Train loss: 0.978\n",
            " the depths of their being to look to lo|ng of metamost manders it is the essenti\n",
            "Epoch 80. Time: 3.593, Train loss: 0.975\n",
            " right imperative for a hardy laborious |corrmit to oh reus much of the will be c\n",
            "Epoch 81. Time: 3.922, Train loss: 0.973\n",
            "remely antipodal to my ears and habits o|nly before the childs it so rut any esti\n",
            "Epoch 82. Time: 3.618, Train loss: 0.970\n",
            "means of our counterparts for the unders|tanding though like and accupulable from\n",
            "Epoch 83. Time: 3.659, Train loss: 0.968\n",
            "d his hatred is artificial and rather un|able for instance to allesman brought fr\n",
            "Epoch 84. Time: 3.915, Train loss: 0.966\n",
            "ysische mensch to what extent useful the|re is also agreek every perspective cont\n",
            "Epoch 85. Time: 3.645, Train loss: 0.965\n",
            "s so dreadful that precisely where he ha|s go art and promiple scheet the value o\n",
            "Epoch 86. Time: 3.702, Train loss: 0.963\n",
            "s into the form of questions from the st|ruggle est from instance has rully in vi\n",
            "Epoch 87. Time: 3.816, Train loss: 0.961\n",
            "umphed over the military and aristocrati|c times i wise may be first still himbus\n",
            "Epoch 88. Time: 3.703, Train loss: 0.956\n",
            "nly by the extent to which the slave may| be fathers contical easicy and do we mu\n",
            "Epoch 89. Time: 3.484, Train loss: 0.955\n",
            "their pond happiness and virtue are no a|pprehent that the way caversal inconsist\n",
            "Epoch 90. Time: 3.766, Train loss: 0.954\n",
            "relationship nor friendship not even enm|ore that his meaned for it is explanatio\n",
            "Epoch 91. Time: 3.899, Train loss: 0.953\n",
            "he eye one must resolutely and radically| deluision and out of givess so hardy ha\n",
            "Epoch 92. Time: 3.450, Train loss: 0.950\n",
            "ency it also separates the pity of the s|cience the praise in the prospect of the\n",
            "Epoch 93. Time: 3.604, Train loss: 0.949\n",
            "od arguments this was the real falseness| at one s ittellection what does as of w\n",
            "Epoch 94. Time: 3.832, Train loss: 0.948\n",
            "e riddles that perplexed and enraptured |by stronger that there unserviousned yei\n",
            "Epoch 95. Time: 3.575, Train loss: 0.948\n",
            "tion to these interests he calls it desi|res that as though strong and ridies tow\n",
            "Epoch 96. Time: 3.425, Train loss: 0.945\n",
            "ntimidate others from certain acts equal| again anti hence are nor the reason to \n",
            "Epoch 97. Time: 4.066, Train loss: 0.944\n",
            "eligious training in the disposition the| luoquistic practice out of himself how \n",
            "Epoch 98. Time: 3.609, Train loss: 0.942\n",
            "happy chances are necessary and many inc|ancualizets what is believed the ascenda\n",
            "Epoch 99. Time: 3.586, Train loss: 0.939\n",
            "apparent end or teleology of the horizon| it pulsently in adorabilits of dissolue\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выводы:\n",
        "1. Построена модель предсказания y(i) по x(i)\n",
        "2. Реализованы обычная полносвязная сеть, RNN, LSTM, GRU\n",
        "3. Наиболее точной оказалась модель GRU\n",
        "4. Применена LSTM для решения лекционного практического задания"
      ],
      "metadata": {
        "id": "3m2I2nzaxaGQ"
      }
    }
  ]
}